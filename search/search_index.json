{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Student Performance ML","text":"<p>Welcome to the documentation for Student Performance ML (stuperml).</p> <p>This project analyzes how AI-assisted learning influences student outcomes and provides a reproducible machine learning pipeline for predicting students' final scores. It is built with PyTorch and follows MLOps best practices such as structured configuration, reproducible environments, testing, and containerization.</p>"},{"location":"#what-this-project-does","title":"What this project does","text":"<ul> <li>Downloads and preprocesses a public dataset on AI usage and student performance.</li> <li>Trains a neural network to predict final exam scores from demographic, study habit, and AI usage features.</li> <li>Evaluates the model against a simple baseline.</li> <li>Exposes a FastAPI-based HTTP service to serve predictions.</li> </ul>"},{"location":"#documentation-structure","title":"Documentation structure","text":"<ul> <li>Home: High-level overview of the project (this page).</li> <li>Usage: How to set up the environment, run preprocessing, train the model, evaluate it, and start the API.</li> <li>Data: Details about the dataset, preprocessing steps, and generated artifacts.</li> <li>Models: Description of the <code>SimpleMLP</code> model, the baseline model, and the training/evaluation procedures.</li> <li>API Reference: HTTP endpoints and auto-generated Python API documentation powered by mkdocstrings.</li> </ul>"},{"location":"#getting-started-quickly","title":"Getting started quickly","text":"<p>From the project root:</p> <ol> <li> <p>Sync dependencies and download the dataset:</p> <p><code>bash uv run invoke sync</code></p> </li> <li> <p>Run preprocessing and generate data artifacts:</p> <p><code>bash uv run src/stuperml/data.py</code></p> </li> <li> <p>Train the model:</p> <p><code>bash uv run src/stuperml/train.py</code></p> </li> <li> <p>Start the prediction API:</p> <p><code>bash uv run uvicorn src.stuperml.api:app --reload</code></p> </li> </ol> <p>For more details, see the Usage page.</p>"},{"location":"api/","title":"API Reference","text":"<p>This page documents the HTTP API and provides auto-generated reference documentation for the main Python modules in the stuperml package.</p>"},{"location":"api/#http-api-stupermlapi","title":"HTTP API (<code>stuperml.api</code>)","text":"<p>The FastAPI application is defined in the <code>stuperml.api</code> module. It exposes endpoints for health checking and batch prediction.</p>"},{"location":"api/#endpoints","title":"Endpoints","text":""},{"location":"api/#get","title":"<code>GET /</code>","text":"<ul> <li>Description: Simple health check endpoint.</li> <li>Response: JSON object with keys:</li> <li><code>message</code>: HTTP status phrase (e.g. <code>\"OK\"</code>).</li> <li><code>status-code</code>: Numeric status code (e.g. <code>200</code>).</li> </ul> <p>Example:</p> <pre><code>curl http://127.0.0.1:8000/\n</code></pre>"},{"location":"api/#post-predict","title":"<code>POST /predict</code>","text":"<ul> <li>Description: Run batch inference on a list of input rows.</li> <li>Request body (<code>PredictionRequest</code>):</li> <li><code>rows</code>: list of objects where each object is a mapping from feature name to value (<code>bool</code>, <code>int</code>, <code>float</code>, or <code>str</code>). Must contain at least one row.</li> <li>Response body (<code>PredictionResponse</code>):</li> <li><code>predictions</code>: list of floating-point predictions, one per input row.</li> </ul> <p>The request features must be compatible with the fitted preprocessor (i.e. same feature names and reasonable data types). If the data cannot be transformed, the endpoint responds with a <code>400 BAD REQUEST</code> containing an error message.</p> <p>On application startup, the API:</p> <ol> <li>Loads the preprocessor from <code>data/preprocessor.joblib</code> (path defined in <code>configs.data_config</code>).</li> <li>Infers the model input size either from <code>preprocessor.get_feature_names_out()</code> or, as a fallback, from <code>data/feature_names.json</code>.</li> <li>Instantiates <code>SimpleMLP</code> with the inferred input size.</li> <li>Loads weights from <code>models/model.pth</code>.</li> </ol> <p>If any of the artifacts are missing, a <code>FileNotFoundError</code> or <code>RuntimeError</code> is raised during startup.</p>"},{"location":"api/#python-api-mkdocstrings","title":"Python API (mkdocstrings)","text":"<p>The sections below are auto-generated from the docstrings in the <code>stuperml</code> package using <code>mkdocstrings</code>. They provide detailed reference information about public classes, functions, and modules.</p>"},{"location":"api/#data","title":"Data","text":""},{"location":"api/#stuperml.data","title":"stuperml.data","text":""},{"location":"api/#stuperml.data.MyDataset","title":"MyDataset","text":"<p>               Bases: <code>Dataset</code></p> Source code in <code>src/stuperml/data.py</code> <pre><code>class MyDataset(Dataset):\n    def __init__(\n        self,\n        split: str = \"train\",\n        cfg: DataConfig = data_config,\n    ) -&gt; None:\n        logger.debug(f\"Initializing MyDataset with split='{split}' and cfg={cfg}\")\n        self.cfg = cfg\n        self.split = split.lower()\n\n        self.X: Optional[torch.Tensor] = None\n        self.y: Optional[torch.Tensor] = None\n\n        if self.split not in {\"train\", \"val\", \"test\"}:\n            logger.error(f\"Invalid split '{self.split}' provided.\")\n            raise ValueError(\"split must be one of: 'train', 'val', 'test'\")\n        logger.info(f\"MyDataset initialized for split '{self.split}'.\")\n\n        x_path = self.cfg.data_folder / f\"X_{self.split}.pt\"\n        y_path = self.cfg.data_folder / f\"y_{self.split}.pt\"\n        if x_path.exists() and y_path.exists() and self._config_matches(self.cfg):\n            logger.debug(f\"Loading preprocessed tensors from {x_path} and {y_path}.\")\n            self.X = torch.load(x_path)\n            self.y = torch.load(y_path)\n            logger.info(f\"Loaded {self.X.size(0)} samples for split '{self.split}'.\")\n        else:\n            logger.warning(f\"Preprocessed data not found at {x_path} and {y_path}. Call preprocess() first.\")\n\n    def __len__(self) -&gt; int:\n        if self.X is None:\n            raise RuntimeError(\"Dataset not initialized with preprocessed tensors.\")\n        return int(self.X.shape[0])\n\n    def __getitem__(self, index: int):\n        if self.X is None or self.y is None:\n            raise RuntimeError(\"Dataset not initialized with preprocessed tensors.\")\n        return self.X[index], self.y[index]\n\n    def preprocess(self) -&gt; None:\n        logger.debug(\"Starting data preprocessing\")\n        self.cfg.data_folder.mkdir(parents=True, exist_ok=True)\n        logger.info(f\"Data folder created/verified: {self.cfg.data_folder}\")\n\n        if self.cfg.gcs_uri:\n            logger.debug(\"Using GCS data source\")\n            if (\n                self.cfg.gcs_service_account_key\n                and \"GOOGLE_APPLICATION_CREDENTIALS\" not in os.environ\n                and os.path.exists(self.cfg.gcs_service_account_key)\n            ):\n                os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = self.cfg.gcs_service_account_key\n            elif self.cfg.gcs_service_account_key and not os.path.exists(self.cfg.gcs_service_account_key):\n                print(\n                    f\"Notice: Service account key '{self.cfg.gcs_service_account_key}' not found. \"\n                    \"Assuming we are running in Cloud Run/Environment with auto-auth.\"\n                )\n\n            gcs_uri = self.cfg.gcs_uri\n            if self.cfg.gcs_data:\n                gcs_uri = f\"{gcs_uri.rstrip('/')}/{self.cfg.gcs_data}\"\n            try:\n                csv_path = _download_csv_from_gcs(gcs_uri, self.cfg.data_folder)\n                logger.info(f\"Downloaded CSV from GCS: {gcs_uri}\")\n            except Exception as e:\n                logger.error(f\"Failed to download CSV from GCS: {e}\")\n                raise\n        else:\n            logger.debug(\"Using Kaggle data source\")\n            csv_path = _download_csv(\"ankushnarwade/ai-impact-on-student-performance\")\n            logger.info(f\"Downloaded CSV from Kaggle dataset: {csv_path}\")\n        df = pd.read_csv(csv_path)\n        logger.debug(f\"CSV loaded into DataFrame with shape {df.shape}\")\n\n        if self.cfg.target_col not in df.columns:\n            logger.error(f\"Target column '{self.cfg.target_col}' not found. Available columns: {list(df.columns)}\")\n            raise KeyError(f\"Target column '{self.cfg.target_col}' not found. Columns: {list(df.columns)}\")\n\n        dropped = self.cfg.dropped_columns\n        train_size = float(self.cfg.train_size)\n        val_size = float(self.cfg.val_size)\n        test_size = float(self.cfg.test_size)\n        seed = int(self.cfg.seed)\n\n        _validate_splits(train_size, val_size, test_size)\n        y_np = df[self.cfg.target_col].to_numpy()\n        X_df = df.drop(columns=[self.cfg.target_col, *dropped], errors=\"ignore\")\n\n        pre = _build_preprocessor()\n        X_np = pre.fit_transform(X_df)\n\n        try:\n            feat_names = pre.get_feature_names_out().tolist()\n        except Exception:\n            feat_names = []\n\n        (X_train, y_train), (X_val, y_val), (X_test, y_test) = _split_data(\n            X_np, y_np, train_size, val_size, test_size, seed\n        )\n\n        torch.save(_to_tensor(X_train), self.cfg.data_folder / \"X_train.pt\")\n        torch.save(_to_tensor(X_val), self.cfg.data_folder / \"X_val.pt\")\n        torch.save(_to_tensor(X_test), self.cfg.data_folder / \"X_test.pt\")\n\n        torch.save(_to_tensor(y_train), self.cfg.data_folder / \"y_train.pt\")\n        torch.save(_to_tensor(y_val), self.cfg.data_folder / \"y_val.pt\")\n        torch.save(_to_tensor(y_test), self.cfg.data_folder / \"y_test.pt\")\n\n        (self.cfg.data_folder / \"feature_names.json\").write_text(json.dumps(feat_names))\n        joblib.dump(pre, self.cfg.data_folder / \"preprocessor.joblib\")\n        self._write_config(self.cfg)\n        logger.info(\"Preprocessing complete - data splits and preprocessor saved.\")\n\n    def _serialize_config(self, cfg: DataConfig) -&gt; dict[str, object]:\n        \"\"\"Return a JSON-serializable snapshot of config for equality checks.\"\"\"\n        config = asdict(cfg)\n        config[\"data_folder\"] = str(cfg.data_folder)\n        config[\"dropped_columns\"] = sorted(cfg.dropped_columns)\n        return config\n\n    def _write_config(self, cfg: DataConfig) -&gt; None:\n        \"\"\"Persist data configuration used to generate artifacts.\"\"\"\n        config_path = cfg.data_folder / \"data_config.json\"\n        config_path.write_text(json.dumps(self._serialize_config(cfg), sort_keys=True))\n\n    def _config_matches(self, cfg: DataConfig) -&gt; bool:\n        \"\"\"Check whether on-disk configuration matches the current config.\"\"\"\n        config_path = cfg.data_folder / \"data_config.json\"\n        if not config_path.exists():\n            return False\n        stored = json.loads(config_path.read_text())\n        current = self._serialize_config(cfg)\n        return stored == current\n\n    def _ensure_preprocessed(self) -&gt; None:\n        \"\"\"Ensure preprocessing artifacts exist and match the current config.\"\"\"\n        required = [\n            self.cfg.data_folder / \"X_train.pt\",\n            self.cfg.data_folder / \"X_val.pt\",\n            self.cfg.data_folder / \"X_test.pt\",\n            self.cfg.data_folder / \"y_train.pt\",\n            self.cfg.data_folder / \"y_val.pt\",\n            self.cfg.data_folder / \"y_test.pt\",\n            self.cfg.data_folder / \"feature_names.json\",\n            self.cfg.data_folder / \"preprocessor.joblib\",\n        ]\n        if not all(path.exists() for path in required) or not self._config_matches(self.cfg):\n            logger.info(\"Preprocessing artifacts missing or config changed; regenerating.\")\n            self.X = None\n            self.y = None\n            self.preprocess()\n\n    def load_data(self) -&gt; tuple[TensorDataset, TensorDataset, TensorDataset]:\n        self._ensure_preprocessed()\n        data_dir: Path\n        data_dir = self.cfg.data_folder\n\n        train_features = torch.load(data_dir / \"X_train.pt\")\n        train_target = torch.load(data_dir / \"y_train.pt\")\n\n        val_features = torch.load(data_dir / \"X_val.pt\")\n        val_target = torch.load(data_dir / \"y_val.pt\")\n\n        test_features = torch.load(data_dir / \"X_test.pt\")\n        test_target = torch.load(data_dir / \"y_test.pt\")\n\n        train_set = TensorDataset(train_features, train_target)\n        val_set = TensorDataset(val_features, val_target)\n        test_set = TensorDataset(test_features, test_target)\n\n        return train_set, val_set, test_set\n</code></pre>"},{"location":"api/#models","title":"Models","text":""},{"location":"api/#stuperml.model","title":"stuperml.model","text":""},{"location":"api/#training","title":"Training","text":""},{"location":"api/#stuperml.train","title":"stuperml.train","text":""},{"location":"api/#stuperml.train.train","title":"train","text":"<pre><code>train(\n    lr: float = 0.001,\n    batch_size: int = 32,\n    epochs: int = 30,\n    verbose: bool = False,\n) -&gt; None\n</code></pre> <p>Train the model and persist artifacts.</p> Source code in <code>src/stuperml/train.py</code> <pre><code>def train(lr: float = 1e-3, batch_size: int = 32, epochs: int = 30, verbose: bool = False) -&gt; None:\n    \"\"\"Train the model and persist artifacts.\"\"\"\n    print(\"Training day and night\")\n\n    timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n    print(f\"Run ID: {timestamp}\")\n\n    print(f\"{lr=}, {batch_size=}, {epochs=}\")\n\n    train_set, val_set, _ = MyDataset(cfg=data_config).load_data()\n    n_features = train_set.tensors[0].shape[1]\n\n    model = SimpleMLP(input_size=n_features).to(DEVICE)\n    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n    val_dataloader = torch.utils.data.DataLoader(val_set, batch_size=batch_size)\n\n    loss_fn = torch.nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    statistics = {\"train_loss\": [], \"val_loss\": []}\n\n    for epoch in range(epochs):\n        model.train()\n        epoch_train_loss = 0.0\n        for index, (features, target) in enumerate(train_dataloader):\n            features, target = features.to(DEVICE), target.to(DEVICE)\n            target = target.view(-1, 1).float()\n\n            optimizer.zero_grad()\n            y_pred = model(features)\n            loss = loss_fn(y_pred, target)\n            loss.backward()\n            optimizer.step()\n\n            epoch_train_loss += loss.item()\n            if verbose:\n                if index % 10 == 0:\n                    print(f\"Epoch {epoch}, iter {index}, \\t train_loss: {loss.item():.5f}\")\n\n        model.eval()\n        epoch_val_loss = 0.0\n        with torch.no_grad():\n            for features, target in val_dataloader:\n                features, target = features.to(DEVICE), target.to(DEVICE)\n                target = target.view(-1, 1).float()\n                y_pred = model(features)\n                v_loss = loss_fn(y_pred, target)\n                epoch_val_loss += v_loss.item()\n\n        avg_train = epoch_train_loss / len(train_dataloader)\n        avg_val = epoch_val_loss / len(val_dataloader)\n        statistics[\"train_loss\"].append(avg_train)\n        statistics[\"val_loss\"].append(avg_val)\n\n        print(f\"Epoch {epoch} \\t Summary: Train Loss: {avg_train:.5f}, \\t Val Loss: {avg_val:.5f}\")\n\n    print(\"Training complete\")\n\n    MODEL_DIR.mkdir(parents=True, exist_ok=True)\n    model_path = MODEL_DIR / f\"model_{timestamp}.pth\"\n    torch.save(model.state_dict(), model_path)\n    print(\"Saved locally.\")\n\n    gcs_models_uri = os.getenv(\"AIP_MODEL_DIR\") or data_config.gcs_models_uri\n    if gcs_models_uri:\n        if (\n            data_config.gcs_service_account_key\n            and \"GOOGLE_APPLICATION_CREDENTIALS\" not in os.environ\n            and os.path.exists(data_config.gcs_service_account_key)\n        ):\n            os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = data_config.gcs_service_account_key\n        _upload_model_artifacts(model_path, gcs_models_uri, timestamp)\n\n    plt.figure(figsize=(10, 5))\n    plt.plot(statistics[\"train_loss\"], label=\"Train Loss\")\n    plt.plot(statistics[\"val_loss\"], label=\"Val Loss\")\n    plt.title(\"Training and Validation Loss\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.savefig(\"src/stuperml/figures/training_validation_epoch_error.png\")\n</code></pre>"},{"location":"api/#evaluation","title":"Evaluation","text":""},{"location":"api/#stuperml.evaluate","title":"stuperml.evaluate","text":""},{"location":"api/#http-api","title":"HTTP API","text":""},{"location":"api/#stuperml.api","title":"stuperml.api","text":""},{"location":"api/#stuperml.api.PredictionRequest","title":"PredictionRequest","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request payload for batch prediction.</p> Source code in <code>src/stuperml/api.py</code> <pre><code>class PredictionRequest(BaseModel):\n    \"\"\"Request payload for batch prediction.\"\"\"\n\n    rows: list[dict[str, bool | int | float | str]] = Field(..., min_length=1)\n</code></pre>"},{"location":"api/#stuperml.api.PredictionResponse","title":"PredictionResponse","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response payload for batch prediction.</p> Source code in <code>src/stuperml/api.py</code> <pre><code>class PredictionResponse(BaseModel):\n    \"\"\"Response payload for batch prediction.\"\"\"\n\n    predictions: list[float]\n</code></pre>"},{"location":"api/#stuperml.api.lifespan","title":"lifespan  <code>async</code>","text":"<pre><code>lifespan(_: FastAPI)\n</code></pre> <p>Load and release model artifacts for app lifecycle.</p> Source code in <code>src/stuperml/api.py</code> <pre><code>@asynccontextmanager\nasync def lifespan(_: FastAPI):\n    \"\"\"Load and release model artifacts for app lifecycle.\"\"\"\n    global _model, _preprocessor\n    _model, _preprocessor = _load_model()\n    try:\n        yield\n    finally:\n        _model = None\n        _preprocessor = None\n</code></pre>"},{"location":"api/#stuperml.api.predict","title":"predict","text":"<pre><code>predict(request: PredictionRequest) -&gt; PredictionResponse\n</code></pre> <p>Run batch inference on input rows.</p> Source code in <code>src/stuperml/api.py</code> <pre><code>@app.post(\"/predict\", response_model=PredictionResponse)\ndef predict(request: PredictionRequest) -&gt; PredictionResponse:\n    \"\"\"Run batch inference on input rows.\"\"\"\n    if _model is None or _preprocessor is None:\n        raise HTTPException(status_code=HTTPStatus.SERVICE_UNAVAILABLE, detail=\"Model not loaded\")\n\n    features_df = pd.DataFrame(request.rows)\n    try:\n        transformed = _preprocessor.transform(features_df)\n    except Exception as exc:\n        raise HTTPException(status_code=HTTPStatus.BAD_REQUEST, detail=str(exc)) from exc\n\n    tensor = torch.as_tensor(transformed, dtype=torch.float32)\n    with torch.no_grad():\n        outputs = _model(tensor).squeeze(1).tolist()\n\n    return PredictionResponse(predictions=[float(value) for value in outputs])\n</code></pre>"},{"location":"api/#stuperml.api.root","title":"root","text":"<pre><code>root() -&gt; dict[str, Any]\n</code></pre> <p>Health check.</p> Source code in <code>src/stuperml/api.py</code> <pre><code>@app.get(\"/\")\ndef root() -&gt; dict[str, Any]:\n    \"\"\"Health check.\"\"\"\n    return {\"message\": HTTPStatus.OK.phrase, \"status-code\": HTTPStatus.OK}\n</code></pre>"},{"location":"data/","title":"Data","text":"<p>This page documents the dataset, preprocessing pipeline, and data artifacts used in the stuperml project.</p>"},{"location":"data/#dataset","title":"Dataset","text":"<p>The project uses the public dataset \"AI Impact on Student Performance\" from Kaggle. It contains approximately 8,000 student records with 26 features describing:</p> <ul> <li>Demographics (e.g., age, grade level)</li> <li>Study habits (e.g., study hours, attendance percentage)</li> <li>Academic performance indicators (e.g., prior exam scores)</li> <li>AI usage metrics (e.g., AI usage time, dependency score, ethical usage score, percentage of AI-generated content)</li> </ul> <p>The primary target variable is the final score of each student.</p> <p>By default, the dataset is downloaded from Kaggle using the helper utilities defined in <code>stuperml.utils</code>. Alternatively, a Google Cloud Storage (GCS) path can be configured in <code>configs/data_config</code> to override the data source.</p>"},{"location":"data/#data-module-stupermldata","title":"Data module (<code>stuperml.data</code>)","text":"<p>All data preparation logic is encapsulated in the <code>MyDataset</code> class defined in the <code>stuperml.data</code> module.</p>"},{"location":"data/#mydataset","title":"<code>MyDataset</code>","text":"<p><code>MyDataset</code> is a <code>torch.utils.data.Dataset</code> wrapper that serves two roles:</p> <ol> <li>Managing preprocessed tensors for the <code>train</code>, <code>val</code>, and <code>test</code> splits.</li> <li>Running the preprocessing pipeline via its <code>preprocess()</code> method.</li> </ol> <p>Key behaviors:</p> <ul> <li>The constructor takes a <code>split</code> argument (<code>\"train\"</code>, <code>\"val\"</code>, or <code>\"test\"</code>) and a <code>DataConfig</code> instance (<code>configs.data_config</code>).</li> <li>If preprocessed tensors already exist under the configured <code>data_folder</code>, they are loaded immediately.</li> <li>If preprocessed tensors are missing, it warns that <code>preprocess()</code> should be run first.</li> <li><code>__len__</code> and <code>__getitem__</code> expose samples in a form compatible with PyTorch <code>DataLoader</code>.</li> </ul>"},{"location":"data/#preprocessing-pipeline","title":"Preprocessing pipeline","text":"<p>The <code>preprocess()</code> method performs the following steps:</p> <ol> <li>Create/verify data folder specified by <code>cfg.data_folder</code>.</li> <li>Download raw CSV:</li> <li>If <code>cfg.gcs_uri</code> is set, it uses <code>_download_csv_from_gcs</code> to retrieve a CSV from Google Cloud Storage.</li> <li>Otherwise, it calls <code>_download_csv</code> with the Kaggle dataset slug <code>\"ankushnarwade/ai-impact-on-student-performance\"</code>.</li> <li>Load CSV into a DataFrame and validate that <code>cfg.target_col</code> exists.</li> <li>Drop configured columns listed in <code>cfg.dropped_columns</code>.</li> <li>Build preprocessing pipeline via <code>_build_preprocessor()</code> from <code>stuperml.utils</code>:</li> <li>Numeric features: standardized using <code>StandardScaler</code>.</li> <li>Categorical/bool features: one-hot encoded using <code>OneHotEncoder</code>.</li> <li>Fit the preprocessor and transform the feature matrix <code>X_df</code>.</li> <li>Split into train/validation/test using <code>_split_data()</code> with proportions from <code>cfg.train_size</code>, <code>cfg.val_size</code>, and <code>cfg.test_size</code> and random seed <code>cfg.seed</code>.</li> <li>Convert to tensors using <code>_to_tensor</code> and save as:</li> <li><code>X_train.pt</code>, <code>X_val.pt</code>, <code>X_test.pt</code></li> <li><code>y_train.pt</code>, <code>y_val.pt</code>, <code>y_test.pt</code></li> <li>Persist artifacts for downstream components:</li> <li><code>feature_names.json</code> (list of transformed feature names)</li> <li><code>preprocessor.joblib</code> (fitted scikit-learn pipeline)</li> </ol>"},{"location":"data/#loading-data","title":"Loading data","text":"<p>The <code>load_data()</code> method loads the saved tensors from disk and returns three <code>TensorDataset</code> objects:</p> <ul> <li><code>train_set</code></li> <li><code>val_set</code></li> <li><code>test_set</code></li> </ul> <p>These datasets are used by the training and evaluation scripts.</p>"},{"location":"data/#utility-functions-stupermlutils","title":"Utility functions (<code>stuperml.utils</code>)","text":"<p>Several helper functions in <code>stuperml.utils</code> are used by the data module:</p> <ul> <li><code>_download_csv(dataset_slug: str) -&gt; Path</code>: Downloads a Kaggle dataset via <code>kagglehub</code> and returns the path to the first CSV file found.</li> <li><code>_download_csv_from_gcs(gcs_uri: str, dest_dir: Path) -&gt; Path</code>: Downloads a CSV from a GCS URI into a local directory. Handles URI parsing, bucket/object resolution, and existence checks.</li> <li><code>_validate_splits(train_size: float, val_size: float, test_size: float)</code>: Ensures that the split ratios are non-negative and sum to 1.0.</li> <li><code>_build_preprocessor() -&gt; ColumnTransformer</code>: Builds a column transformer that scales numerical columns and one-hot encodes categorical and boolean columns.</li> <li><code>_split_data(...) -&gt; Tuple[Tuple, Tuple, Tuple]</code>: Splits features and targets into train/validation/test arrays using <code>train_test_split</code> with flexible handling of zero-sized splits.</li> <li><code>_to_tensor(x, dtype=torch.float32) -&gt; torch.Tensor</code>: Converts numpy arrays to PyTorch tensors.</li> </ul> <p>These utilities are also used indirectly by evaluation and the API through the artifacts produced by <code>MyDataset</code>.</p>"},{"location":"data/#data-quality-report","title":"Data quality report","text":"<p>Running <code>uv run src/stuperml/data.py</code> not only preprocesses the data but also generates a simple data quality report and a distribution plot:</p> <ul> <li>Prints a markdown table summarizing for each split:</li> <li>Number of samples</li> <li>Number of features</li> <li>Mean and standard deviation of the target</li> <li>Whether NaN values are present</li> <li>Saves a KDE plot of the target distribution for train/val/test to <code>reports/figures/dist_plot.png</code>.</li> </ul> <p>This makes it easy to visually inspect potential distribution shift across splits.</p>"},{"location":"data/#summary-of-artifacts","title":"Summary of artifacts","text":"<p>After preprocessing, you should see at least the following under the configured <code>data_folder</code>:</p> <ul> <li><code>X_train.pt</code>, <code>X_val.pt</code>, <code>X_test.pt</code></li> <li><code>y_train.pt</code>, <code>y_val.pt</code>, <code>y_test.pt</code></li> <li><code>feature_names.json</code></li> <li><code>preprocessor.joblib</code></li> </ul> <p>And under <code>reports/figures/</code>:</p> <ul> <li><code>dist_plot.png</code> (target distribution across splits).</li> </ul>"},{"location":"models/","title":"Models","text":"<p>This page describes the baseline and neural network models implemented in the stuperml project, as well as how they are trained and evaluated.</p>"},{"location":"models/#model-module-stupermlmodel","title":"Model module (<code>stuperml.model</code>)","text":"<p>The core model definitions live in the <code>stuperml.model</code> module.</p>"},{"location":"models/#simplemlp","title":"<code>SimpleMLP</code>","text":"<p><code>SimpleMLP</code> is a feed-forward neural network implemented using <code>torch.nn.Module</code>. It is used to predict the final student score from the preprocessed feature vector.</p> <p>Architecture:</p> <ul> <li>Input layer: size equals the number of preprocessed features.</li> <li>Hidden layer 1: <code>Linear(input_size, 64)</code> + <code>ReLU</code> activation.</li> <li>Hidden layer 2: <code>Linear(64, 32)</code> + <code>ReLU</code> activation.</li> <li>Output layer: <code>Linear(32, 1)</code> (scalar regression output).</li> </ul> <p>Additional behaviors:</p> <ul> <li>Logs debug information upon initialization (input size, successful construction).</li> <li>Warns via the logger if NaN values appear in the output during the forward pass.</li> </ul> <p>This model is used in both training (<code>stuperml.train</code>) and evaluation (<code>stuperml.evaluate</code>), as well as by the API (<code>stuperml.api</code>).</p>"},{"location":"models/#meanbasemodel","title":"<code>MeanBaseModel</code>","text":"<p><code>MeanBaseModel</code> is a simple baseline model for regression tasks. It learns only the mean of the target variable on the training set and always predicts this constant value for any input.</p> <p>Key properties:</p> <ul> <li>Takes a target tensor at initialization and computes its mean value.</li> <li>Registers the mean as a buffer so it moves correctly across devices.</li> <li>Validates that the target tensor is non-empty and logs errors or critical issues if the mean is NaN.</li> <li>The <code>forward</code> method returns a tensor of shape <code>(batch_size, 1)</code> where every element equals the stored mean.</li> </ul> <p>This baseline allows you to compare the performance of <code>SimpleMLP</code> against a naive \"predict-the-mean\" strategy.</p>"},{"location":"models/#training-stupermltrain","title":"Training (<code>stuperml.train</code>)","text":"<p>The training script defines a <code>train</code> function that orchestrates loading data, initializing the model, and running the optimization loop.</p> <p>High-level steps:</p> <ol> <li>Determine the device: CUDA, Apple MPS (if available), or CPU.</li> <li>Load train and validation splits via <code>MyDataset(cfg=data_config).load_data()</code>.</li> <li>Infer the number of input features from the training tensors.</li> <li>Instantiate a <code>SimpleMLP</code> model with the computed input size.</li> <li>Create PyTorch <code>DataLoader</code> instances for train and validation data.</li> <li>Use Mean Squared Error (MSE) loss and the Adam optimizer.</li> <li>For each epoch:</li> <li>Train the model and accumulate training loss.</li> <li>Evaluate on the validation set and accumulate validation loss.</li> <li>Optionally print intermediate training loss if <code>verbose</code> is enabled.</li> <li>Track epoch-wise training and validation losses in a <code>statistics</code> dictionary.</li> <li>Save the final model weights to <code>models/model.pth</code>.</li> <li>Generate and save a loss curve figure to <code>src/stuperml/figures/training_validation_epoch_error.png</code>.</li> </ol> <p>The <code>train</code> function is exposed via <code>typer</code>, so you can call it from the command line with configurable hyperparameters. See the Usage page for examples.</p>"},{"location":"models/#evaluation-stupermlevaluate","title":"Evaluation (<code>stuperml.evaluate</code>)","text":"<p>The evaluation script defines an <code>evaluate</code> function, also exposed via <code>typer</code>, which loads a trained model and computes metrics on the test set.</p> <p>Workflow:</p> <ol> <li>Load the test set tensors from disk via <code>MyDataset(cfg=data_config).load_data()</code>.</li> <li>Instantiate a <code>SimpleMLP</code> model with the correct input size.</li> <li>Load the model checkpoint from the provided path.</li> <li>Wrap the test split in a <code>DataLoader</code> with a default batch size of 32.</li> <li>Set the model to evaluation mode and iterate over batches without gradient computation.</li> <li>Compute the Mean Absolute Error (MAE) across all test samples.</li> <li>Log the MAE and emit a warning if it exceeds a threshold (10.0 by default).</li> <li>Collect residuals (target - prediction) and plot their distribution.</li> <li>Save the residual histogram to <code>src/stuperml/figures/residual_distribution.png</code>.</li> </ol> <p>This evaluation routine provides both a scalar performance metric and a visual diagnostic of model errors.</p>"},{"location":"models/#figures","title":"Figures","text":"<p>Training and evaluation generate the following figures under <code>src/stuperml/figures/</code>:</p> <ul> <li><code>training_validation_epoch_error.png</code>: Training and validation loss over epochs.</li> <li><code>residual_distribution.png</code>: Histogram of residuals on the test set.</li> </ul> <p>These plots can be included in reports or inspected manually to understand learning dynamics and error characteristics.</p>"},{"location":"usage/","title":"Usage","text":"<p>This page describes how to set up the environment, prepare the data, train the model, and serve predictions for the stuperml project.</p>"},{"location":"usage/#prerequisites","title":"Prerequisites","text":"<ul> <li>macOS (project is developed and tested primarily on macOS)</li> <li>Python environment managed via <code>uv</code> (installed on your system)</li> <li>Internet access to download the dataset (Kaggle or GCS, depending on configuration)</li> </ul>"},{"location":"usage/#environment-setup","title":"Environment setup","text":"<p>From the project root:</p> <ol> <li>Install dependencies and fetch the dataset using the project tasks:</li> </ol> <pre><code>uv run invoke sync\n</code></pre> <ol> <li>Optionally run formatting and linting:</li> </ol> <pre><code>uv run ruff format .\nuv run ruff check . --fix\n</code></pre> <ol> <li>(Optional) Run tests to verify everything is working:</li> </ol> <pre><code>uv run pytest tests/\n</code></pre>"},{"location":"usage/#data-preparation","title":"Data preparation","text":"<p>Data handling is implemented in the <code>MyDataset</code> class defined in the <code>stuperml.data</code> module.</p> <p>To run the full preprocessing pipeline and generate the train/validation/test splits, preprocessor, and feature name artifacts, execute:</p> <pre><code>uv run src/stuperml/data.py\n</code></pre> <p>This will:</p> <ul> <li>Download the raw CSV either from Kaggle (default) or from GCS, depending on the configuration in <code>configs/data_config</code>.</li> <li>Build a preprocessing pipeline (scaling numeric features and one-hot encoding categorical features).</li> <li>Split the dataset into train/validation/test according to the configured ratios.</li> <li>Save the following artifacts under the configured <code>data_folder</code> (by default <code>data/</code>):</li> <li><code>X_train.pt</code>, <code>X_val.pt</code>, <code>X_test.pt</code></li> <li><code>y_train.pt</code>, <code>y_val.pt</code>, <code>y_test.pt</code></li> <li><code>preprocessor.joblib</code></li> <li><code>feature_names.json</code></li> </ul> <p>These artifacts are consumed later by training, evaluation, and the API.</p>"},{"location":"usage/#training-the-model","title":"Training the model","text":"<p>Model training logic lives in <code>stuperml.train</code>. To train the neural network from the preprocessed data:</p> <pre><code>uv run src/stuperml/train.py\n</code></pre> <p>The <code>train</code> command supports several configurable parameters:</p> <ul> <li><code>lr</code>: learning rate (default: <code>1e-3</code>)</li> <li><code>batch_size</code>: batch size (default: <code>32</code>)</li> <li><code>epochs</code>: number of training epochs (default: <code>30</code>)</li> <li><code>verbose</code>: whether to print per-iteration logs</li> </ul> <p>Example with custom hyperparameters:</p> <pre><code>uv run src/stuperml/train.py --lr 0.0005 --batch-size 64 --epochs 50 --verbose\n</code></pre> <p>During training the script will:</p> <ul> <li>Load train and validation tensors from the data folder.</li> <li>Initialize a <code>SimpleMLP</code> model on CPU, CUDA, or Apple MPS, depending on availability.</li> <li>Train using Mean Squared Error (MSE) loss and Adam optimizer.</li> <li>Track training and validation loss over epochs.</li> <li>Save the trained model weights to <code>models/model.pth</code>.</li> <li>Produce a training curve figure at <code>src/stuperml/figures/training_validation_epoch_error.png</code>.</li> </ul>"},{"location":"usage/#evaluating-the-model","title":"Evaluating the model","text":"<p>Evaluation logic is implemented in <code>stuperml.evaluate</code>. To evaluate a saved checkpoint on the test split:</p> <pre><code>uv run src/stuperml/evaluate.py --model-checkpoint models/model.pth\n</code></pre> <p>This will:</p> <ul> <li>Load the test split tensors from the data folder.</li> <li>Instantiate a new <code>SimpleMLP</code> model with the correct input size.</li> <li>Load the checkpoint weights.</li> <li>Compute the Mean Absolute Error (MAE) over the test set.</li> <li>Save a residual distribution histogram to <code>src/stuperml/figures/residual_distribution.png</code>.</li> </ul> <p>If the MAE is high (greater than 10.0), a warning is logged to highlight potential performance issues.</p>"},{"location":"usage/#serving-predictions-via-api","title":"Serving predictions via API","text":"<p>The project exposes a FastAPI-based HTTP API defined in <code>stuperml.api</code>. To start the API locally:</p> <pre><code>uv run uvicorn src.stuperml.api:app --reload\n</code></pre> <p>By default the app runs on <code>http://127.0.0.1:8000</code>.</p> <p>On startup, the service will:</p> <ul> <li>Load the trained model from <code>models/model.pth</code>.</li> <li>Load the preprocessor from <code>data/preprocessor.joblib</code>.</li> <li>Infer the model input size from the preprocessor or from <code>data/feature_names.json</code>.</li> </ul>"},{"location":"usage/#health-check","title":"Health check","text":"<p>You can verify the service is running by calling the root endpoint:</p> <pre><code>curl http://127.0.0.1:8000/\n</code></pre> <p>Expected response:</p> <pre><code>{\"message\": \"OK\", \"status-code\": 200}\n</code></pre>"},{"location":"usage/#batch-prediction-endpoint","title":"Batch prediction endpoint","text":"<p>To perform batch predictions, use the <code>/predict</code> endpoint with a JSON payload containing a <code>rows</code> list. Each row is a dictionary mapping feature names to values, matching the schema used during preprocessing.</p> <p>Example request:</p> <pre><code>curl -X POST \"http://127.0.0.1:8000/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"rows\": [\n      {\n        \"Age\": 18,\n        \"Study_Hours\": 3.5,\n        \"Attendance\": 92.0,\n        \"AI_Usage_Time\": 2.0,\n        \"AI_Dependency_Score\": 4,\n        \"AI_Ethical_Score\": 8,\n        \"AI_Generated_Content_Percentage\": 15.0\n      }\n    ]\n  }'\n</code></pre> <p>The response contains a list of predicted final scores:</p> <pre><code>{\n  \"predictions\": [72.3]\n}\n</code></pre> <p>If the payload cannot be transformed by the preprocessor (for example due to missing or unexpected features), the service returns a <code>400 BAD REQUEST</code> error with a descriptive message.</p>"},{"location":"usage/#command-summary","title":"Command summary","text":"<ul> <li>Sync dependencies and fetch dataset: <code>uv run invoke sync</code></li> <li>Run preprocessing and data report: <code>uv run src/stuperml/data.py</code></li> <li>Train model: <code>uv run src/stuperml/train.py [--lr ... --batch-size ... --epochs ... --verbose]</code></li> <li>Evaluate model: <code>uv run src/stuperml/evaluate.py --model-checkpoint models/model.pth</code></li> <li>Start API: <code>uv run uvicorn src.stuperml.api:app --reload</code></li> </ul>"}]}